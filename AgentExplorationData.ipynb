{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8c300bbbd0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = Display(backend=\"xvnc\", size=(64,64), visible=0, rfbport=5901)\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8c300bbbd0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnityTimeOutException",
     "evalue": "The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents' Behavior Parameters > Behavior Type is set to \"Default\"\n\t The environment and the Python interface have compatible versions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityTimeOutException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-1d501e40addf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RC.x86_64\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_wait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mlagents_envs/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, seed, no_graphics, timeout_wait, additional_args, side_channels, log_folder)\u001b[0m\n\u001b[1;32m    215\u001b[0m         )\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0maca_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maca_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mlagents_envs/environment.py\u001b[0m in \u001b[0;36m_send_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInputProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mlagents_envs/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityInputProto\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutputProto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll_for_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0maca_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityMessageProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/mlagents_envs/rpc_communicator.py\u001b[0m in \u001b[0;36mpoll_for_timeout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout_wait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise UnityTimeOutException(\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0;34m\"The Unity environment took too long to respond. Make sure that :\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;34m\"\\t The environment does not need user interaction to launch\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'\\t The Agents\\' Behavior Parameters > Behavior Type is set to \"Default\"\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnityTimeOutException\u001b[0m: The Unity environment took too long to respond. Make sure that :\n\t The environment does not need user interaction to launch\n\t The Agents' Behavior Parameters > Behavior Type is set to \"Default\"\n\t The environment and the Python interface have compatible versions."
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"RC.x86_64\", seed=1, timeout_wait=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths='./Datasets/50k/actor-26-traj-1.pkl'\n",
    "if not os.path.exists(filepaths):\n",
    "    os.makedirs(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import os.path\n",
    "import shutil\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import deque, defaultdict, namedtuple\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Counter:\n",
    "  def __init__(self, init_val: int = 0):\n",
    "    self._val = mp.RawValue(\"i\", init_val)\n",
    "    self._lock = mp.Lock()\n",
    "\n",
    "  def increment(self):\n",
    "    with self._lock:\n",
    "      self._val.value += 1\n",
    "\n",
    "  @property\n",
    "  def value(self):\n",
    "    with self._lock:\n",
    "      return self._val.value\n",
    "\n",
    "class Timer():\n",
    "  def __init__(self, maxsize=20):\n",
    "    self.values = deque(maxlen=maxsize)\n",
    "    self.count = 0.\n",
    "    self.sum = 0.\n",
    "\n",
    "  def update(self, value):\n",
    "    self.values.append(value)\n",
    "    self.sum += value\n",
    "    self.count += 1\n",
    "\n",
    "  @property\n",
    "  def avg(self):\n",
    "    return np.mean(self.values)\n",
    "\n",
    "  @property\n",
    "  def global_avg(self):\n",
    "    return self.sum / self.count\n",
    "\n",
    "class MetricLogger():\n",
    "  def __init__(self):\n",
    "    self.values = defaultdict(Timer)\n",
    "\n",
    "  def update(self, **kargs):\n",
    "    for key, value in kargs.items():\n",
    "      self.values[key].update(value)\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    return self.values[key]\n",
    "\n",
    "  def __setitem__(self, key, value):\n",
    "    self.values[key].update(value)\n",
    "\n",
    "def dec_agent_pos_rot(pos_rot_vec):\n",
    "  pos = pos_rot_vec[:3]\n",
    "  rot = pos_rot_vec[3:]\n",
    "  return pos, rot\n",
    "\n",
    "def dec_building_pos_scale(pos_scale_vec):\n",
    "  pos = pos_scale_vec[:27].reshape(9, 3)\n",
    "  scale = pos_scale_vec[27:54].reshape(9, 3)\n",
    "  \n",
    "  return pos, scale\n",
    "\n",
    "def comp_min_distance_angle(agent_pos, building_pos, building_scale):\n",
    "  \"\"\"\n",
    "  agent_pos: (3,)\n",
    "  building_pos: (9, 3)\n",
    "  building_scale: (9, 3)\n",
    "  \n",
    "  compute agent and building distance on x-z plane.\n",
    "  \"\"\"\n",
    "  \n",
    "  num_building = np.sum(np.sum(building_pos, axis=1) != 0)\n",
    "  \n",
    "  dis = (agent_pos - building_pos)**2\n",
    "  dis = np.sqrt(dis[:, 0] + dis[:, 2])\n",
    "  \n",
    "  building_radius = (building_scale / 2.)**2\n",
    "  building_radius = np.sqrt(building_radius[:, 0] + building_radius[:, 2])\n",
    "  \n",
    "  dis = dis - building_radius + 5. # distance to the building surface\n",
    "  \n",
    "  dis_min_idx = np.argmin(dis[:num_building])\n",
    "  \n",
    "  min_building_pos = building_pos[dis_min_idx]\n",
    "  dis_min = dis[dis_min_idx]\n",
    "  \n",
    "  x_offset = min_building_pos[0] - agent_pos[0]\n",
    "  z_offset = min_building_pos[2] - agent_pos[2]\n",
    "  cos_theta = x_offset / (np.sqrt(x_offset**2 + z_offset**2) + 1e-5)\n",
    "  sin_theta = z_offset / (np.sqrt(x_offset**2 + z_offset**2) + 1e-5)\n",
    "  \n",
    "  theta = np.degrees(np.arcsin(sin_theta))\n",
    "  if np.isnan(theta):\n",
    "    pdb.set_trace()\n",
    "  if cos_theta < 0.:\n",
    "    theta = 180. - theta\n",
    "    \n",
    "  theta = theta % 360.\n",
    "  return dis_min, theta\n",
    "\n",
    "def dec_top_down_map(building_pos_scale_color):\n",
    "  pos = building_pos_scale_color[:27].reshape(9, 3)\n",
    "  scale = building_pos_scale_color[27:54].reshape(9, 3)\n",
    "  color = building_pos_scale_color[54:].reshape(9, 3)\n",
    "  \n",
    "  num_building = np.sum(np.sum(pos, axis=1) != 0)\n",
    "\n",
    "  height = scale[:num_building, 1]\n",
    "  \n",
    "  top_down_map = np.zeros((num_building, 64, 64, 3))\n",
    "  \n",
    "  for i in range(num_building):\n",
    "    pos_i_x = (pos[i, 0] + 50) / 100 * 64\n",
    "    pos_i_z = (pos[i, 2] + 50) / 100 * 64\n",
    "    \n",
    "    scale_i_x = scale[i, 0] / 100 * 64\n",
    "    scale_i_z = scale[i, 2] / 100 * 64\n",
    "    \n",
    "    top_down_map[i][64 - int(pos_i_z + scale_i_z // 2) : 64 - int(pos_i_z - scale_i_z // 2 + 1),\n",
    "                   int(pos_i_x - scale_i_x // 2) : int(pos_i_x + scale_i_x // 2 + 1)] = color[i]\n",
    "    \n",
    "  sort_idx = np.argsort(height)\n",
    "  maps = np.zeros((64, 64, 3))\n",
    "\n",
    "  for idx in sort_idx:\n",
    "    \n",
    "    overlap = (maps > 0.) * (top_down_map[idx] > 0.)\n",
    "    \n",
    "    maps = maps * (1. - overlap) + top_down_map[idx]\n",
    "    \n",
    "  return maps\n",
    "\n",
    "def plot_traj(map_top_down, agent_pos):\n",
    "  \"\"\"\n",
    "  agent_pos: T, 2\n",
    "  \"\"\"\n",
    "  \n",
    "  agent_pos = np.array(agent_pos) + 50\n",
    "  \n",
    "  im = Image.fromarray((map_top_down * 255).astype(np.uint8))\n",
    "  draw = ImageDraw.Draw(im)\n",
    "  num = agent_pos.shape[0]\n",
    "  start = agent_pos[0]\n",
    "  for i in range(1, num):\n",
    "    end = agent_pos[i]\n",
    "    draw.line(\n",
    "      (int(start[0] / 100 * 64), int((100 - start[1]-1) / 100 * 64),\n",
    "        int(end[0] / 100 * 64), int((100 - end[1]-1) / 100 * 64)),\n",
    "      fill='red',\n",
    "      width = 1,\n",
    "    )\n",
    "    start = end\n",
    "    \n",
    "  return np.asarray(im, dtype='int32')\n",
    "\n",
    "def plot_traj_step(map_top_down, agent_pos):\n",
    "  \"\"\"\n",
    "  agent_pos: T, 2\n",
    "  map_top_down: H, W, C\n",
    "  \"\"\"\n",
    "  \n",
    "  agent_pos = np.array(agent_pos) + 50\n",
    "  \n",
    "  im = Image.fromarray((map_top_down * 255).astype(np.uint8))\n",
    "  draw = ImageDraw.Draw(im)\n",
    "  num = agent_pos.shape[0]\n",
    "  start = agent_pos[0]\n",
    "  map_traj_list = []\n",
    "  for i in range(num):\n",
    "    end = agent_pos[i]\n",
    "    draw.line(\n",
    "      (int(start[0] / 100 * 64), int((100 - start[1]-1) / 100 * 64),\n",
    "        int(end[0] / 100 * 64), int((100 - end[1]-1) / 100 * 64)),\n",
    "      fill='red',\n",
    "      width = 1,\n",
    "    )\n",
    "    start = end\n",
    "    map_traj_list.append(np.asarray(im, dtype='int32'))\n",
    "\n",
    "  map_traj = np.array(map_traj_list).astype(np.float) / 255. # B, H, W, C\n",
    "    \n",
    "  return map_traj\n",
    "\n",
    "def agent_building_angle(agent_pos, agent_rot, building_pos, building_scale):\n",
    "  \"\"\"\n",
    "  agent_rot: scalar\n",
    "  agent_pos: (3,)\n",
    "  building_pos: (9, 3)\n",
    "  building_scale: (9, 3)\n",
    "  \n",
    "  compute agent and building distance on x-z plane.\n",
    "  \"\"\"\n",
    "  \n",
    "  num_building = np.sum(np.sum(building_pos, axis=1) != 0)\n",
    "  \n",
    "  x_offset = building_pos[:num_building, 0] - agent_pos[0]\n",
    "  z_offset = building_pos[:num_building, 2] - agent_pos[2]\n",
    "  cos_theta = x_offset / (np.sqrt(x_offset**2 + z_offset**2) + 1e-5)\n",
    "  sin_theta = z_offset / (np.sqrt(x_offset**2 + z_offset**2) + 1e-5)\n",
    "  \n",
    "  theta = np.degrees(np.arcsin(sin_theta))\n",
    "  if np.isnan(theta).any():\n",
    "    pdb.set_trace()\n",
    "  for i in range(num_building):\n",
    "    if cos_theta[i] < 0.:\n",
    "      theta[i] = 180. - theta[i]\n",
    "    \n",
    "  theta = theta % 360.\n",
    "  \n",
    "  agent_rot_ = (-agent_rot + 90) % 360 # opposite rotation direction, agent facing y+ is 0 rotation\n",
    "  angle_diff = abs(agent_rot_ - theta)\n",
    "\n",
    "  return theta, angle_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from actor_unity_gen_data import Actor\n",
    "# from env_utils import *\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, hid_channels, out_channels,\n",
    "                 kernel_size_1, stride_1, padding_1,\n",
    "                 kernel_size_2, stride_2, padding_2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            Conv2dBlock(in_channels, hid_channels, kernel_size_1, stride_1, padding_1),\n",
    "            Conv2dBlock(hid_channels, out_channels, kernel_size_2, stride_2, padding_2))\n",
    "        \n",
    "        self.skip = Conv2dBlock(in_channels, out_channels, kernel_size_2, stride_2, padding_2)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.main(x) + self.skip(x)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "class Conv2dBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.m = conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.weight = nn.Parameter(torch.ones(out_channels))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.m(x)\n",
    "        return F.relu(F.group_norm(x, 8, self.weight, self.bias))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def conv2d(in_channels, out_channels, kernel_size, stride=1,\n",
    "           padding=0, dilation=1, groups=1,\n",
    "           bias=True, padding_mode='zeros',\n",
    "           weight_init='kaiming'):\n",
    "    \n",
    "    m = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n",
    "                  padding, dilation, groups, bias, padding_mode)\n",
    "    \n",
    "    if weight_init == 'xavier':\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "    else:\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "    \n",
    "    if bias:\n",
    "        nn.init.zeros_(m.bias)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class GaussianWithConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(GaussianWithConv2d, self).__init__()\n",
    "        \n",
    "        self.enc = conv2d(c_in, 2 * c_out, 5, 1, 2, weight_init='xavier')\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # type: (Tensor) -> Tuple[Tensor, Tensor]\n",
    "        mu, std = self.enc(inputs).chunk(2, 1)\n",
    "        std = F.softplus(std) + 1e-5\n",
    "        return mu, std\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "class GatedCNN(nn.Module):\n",
    "  \n",
    "  def __init__(self, input_size, hidden_size):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv_h = nn.Conv2d(input_size, hidden_size*2, 5, 1, 2)\n",
    "    # self.conv_h = nn.Conv2d(64, hidden_size*2, 3, 1, 1)\n",
    "    \n",
    "  def forward(self, h, x):\n",
    "    \n",
    "    h = self.conv_h(torch.cat([x, h], dim=1))\n",
    "    # h = self.conv_h(x + h)\n",
    "    \n",
    "    h1, h2 = torch.chunk(h, 2, dim=1)\n",
    "    h = torch.tanh(h1) * torch.sigmoid(h2)\n",
    "    \n",
    "    return h\n",
    "    \n",
    "class AgentCoreBaseVisEncoder(nn.Module):\n",
    "  def __init__(self, c_in, c_out):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv = nn.Conv2d(c_in, c_out, 3, 1, 1)\n",
    "    self.pad = nn.ZeroPad2d((0, 1, 0, 1))\n",
    "    self.max_pool = nn.MaxPool2d(3, 2)\n",
    "    self.residual = ResidualBlock(c_out, c_out, c_out, 3, 1, 1, 3, 1, 1)\n",
    "\n",
    "    self.net = nn.Sequential(self.pad, self.conv, self.max_pool, self.residual)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.net(x)\n",
    "\n",
    "class AgentCoreDeepVisEncoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.block_1 = AgentCoreBaseVisEncoder(3, 16)\n",
    "    self.block_2 = AgentCoreBaseVisEncoder(16, 32)\n",
    "    self.block_3 = AgentCoreBaseVisEncoder(32, 32)\n",
    "    \n",
    "    self.fc = nn.Linear(8*8*32, 256)\n",
    "\n",
    "    self.net = nn.Sequential(self.block_1, self.block_2, self.block_3, nn.Flatten(), nn.ReLU(), self.fc, nn.ReLU())\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.net(x)\n",
    "\n",
    "def weight_init(m): \n",
    "  if isinstance(m, nn.Linear):\n",
    "    init.normal_(m.weight, std=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from utils import *\n",
    "from torch.distributions import Categorical\n",
    "import pdb\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  \n",
    "  def __init__(self, action_dim):\n",
    "    \n",
    "    super().__init__()\n",
    "    self.visual_enc = AgentCoreDeepVisEncoder().to(device)\n",
    "    \n",
    "    self.agent_core = nn.LSTM(256, hidden_dim, batch_first=True).to(device)\n",
    "    \n",
    "    self.action_layer = nn.Sequential(\n",
    "      nn.Linear(hidden_dim, action_dim),\n",
    "    ).to(device)\n",
    "    \n",
    "    self.value_layer = nn.Sequential(\n",
    "      nn.Linear(hidden_dim, 1),\n",
    "    ).to(device)\n",
    "    self.action_dim = action_dim\n",
    "\n",
    "    self.dist = Categorical\n",
    "\n",
    "  def forward(self, x, done, states):\n",
    "\n",
    "    B, T, C, H, W = x.shape\n",
    "\n",
    "    h, c = states # 1, B, H\n",
    "\n",
    "    x_t_enc = self.visual_enc(x.reshape(B*T, C, H, W)).reshape(B, T, -1)\n",
    "\n",
    "    states_h = []\n",
    "    states_c = []\n",
    "\n",
    "    for t in range(T):\n",
    "\n",
    "      o, (h, c) = self.agent_core(x_t_enc[:, t:t+1], (h, c))\n",
    "      \n",
    "      h = h * done[:, t:t+1]\n",
    "      c = c * done[:, t:t+1]\n",
    "\n",
    "      states_h.append(h)\n",
    "      states_c.append(c)\n",
    "\n",
    "    states_h = torch.cat(states_h, dim=0).permute(1,0,2) # B, T, H\n",
    "    states_c = torch.cat(states_c, dim=0).permute(1,0,2)\n",
    "\n",
    "    value = self.value_layer(states_h) # B, T, 1\n",
    "    action_logits = self.action_layer(states_h) # B, T, dim_action\n",
    "\n",
    "    return states_h, states_c, value.squeeze(-1), action_logits\n",
    "\n",
    "  def act(self, x_t, h, c, deterministic=False):\n",
    "\n",
    "    x_t_enc = self.visual_enc(x_t)\n",
    "\n",
    "    o, (h, c) = self.agent_core(x_t_enc.unsqueeze(0), (h, c))\n",
    "\n",
    "    action_logits = self.action_layer(o.squeeze(0))\n",
    "\n",
    "    dist = self.dist(logits=action_logits)\n",
    "\n",
    "    if deterministic:\n",
    "      actions = torch.argmax(action_logits, dim=-1, keepdim=True)\n",
    "    else:\n",
    "      actions = dist.sample()\n",
    "\n",
    "    log_prob = dist.log_prob(actions)\n",
    "\n",
    "    return actions, log_prob, h, c\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class MapDecoder(nn.Module):\n",
    "  \n",
    "  def __init__(self, ):\n",
    "    \n",
    "    super().__init__()\n",
    "    \n",
    "    #TODO\n",
    "    # self.dec = nn.Sequential(\n",
    "    #   nn.ConvTranspose2d(hidden_dim*2, 256, 4, 4),\n",
    "    #   nn.ReLU(),\n",
    "    #   nn.ConvTranspose2d(256, 128, 4, 4),\n",
    "    #   nn.ReLU(),\n",
    "    #   nn.ConvTranspose2d(128, 64, 4, 4),\n",
    "    #   nn.ReLU(),\n",
    "    #   nn.Conv2d(64, 3, 3, 1, 1)\n",
    "    # ).to(device)\n",
    "    self.dec = nn.Sequential(\n",
    "      Conv2dBlock(hidden_dim*2, 256*4*4, 1, 1, 0),\n",
    "      nn.PixelShuffle(4),\n",
    "      Conv2dBlock(256, 128*4*4, 3, 1, 1),\n",
    "      nn.PixelShuffle(4),\n",
    "      Conv2dBlock(128, 64*4*4, 3, 1, 1),\n",
    "      nn.PixelShuffle(4),\n",
    "      nn.Conv2d(64, 3, 3, 1, 1),\n",
    "      nn.Sigmoid()\n",
    "    ).to(device)\n",
    "    \n",
    "\n",
    "  def forward(self, h, map_gt, done):\n",
    "    map_pred = self.dec(h.unsqueeze(-1).unsqueeze(-1))\n",
    "    loss = ((map_pred - map_gt).pow(2).sum(dim=(1,2,3)) * done).mean()\n",
    "    return map_pred, loss\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class PositionDecoder(nn.Module):\n",
    "  \n",
    "  def __init__(self, ):\n",
    "    \n",
    "    super().__init__()\n",
    "    \n",
    "    self.dec = nn.Sequential(\n",
    "      nn.Linear(hidden_dim*2, pos_dim),\n",
    "    ).to(device)\n",
    "    \n",
    "  def forward(self, h, pos_gt, done):\n",
    "    pos_cls_gt = pos_gt[:, 0]*10 + pos_gt[:, 1] # 0~99\n",
    "    pos_pred = self.dec(h)\n",
    "    pos_acc = ((pos_pred.argmax(dim=1) * done).long() == (pos_cls_gt * done).long()).float().mean()\n",
    "    loss = F.cross_entropy(pos_pred, pos_cls_gt.long(), reduction='none')\n",
    "    loss = (loss * done).mean()\n",
    "    return pos_acc, loss\n",
    "\n",
    "class RotDecoder(nn.Module):\n",
    "  \n",
    "  def __init__(self, ):\n",
    "    \n",
    "    super().__init__()\n",
    "    \n",
    "    self.dec = nn.Sequential(\n",
    "      nn.Linear(hidden_dim*2, rot_dim),\n",
    "    ).to(device)\n",
    "    \n",
    "  def forward(self, h, rot_gt, done):\n",
    "    rot_pred = self.dec(h)\n",
    "    rot_acc = ((rot_pred.argmax(dim=1)*done).long() == (rot_gt*done).long()).float().mean()\n",
    "\n",
    "    loss = F.cross_entropy(rot_pred, rot_gt.long(), reduction='none')\n",
    "    loss = (loss * done).mean()\n",
    "    return rot_acc, loss\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "class ConvDraw(nn.Module):\n",
    "  \n",
    "  def __init__(self, ):\n",
    "    \n",
    "    super().__init__()\n",
    "    \n",
    "    self.img_enc = nn.Sequential(\n",
    "      Conv2dBlock(3*2, 16, 4, 2, 1),\n",
    "      Conv2dBlock(16, 16, 4, 2, 1),\n",
    "      Conv2dBlock(16, 64, 4, 2, 1),\n",
    "    ).to(device)\n",
    "    \n",
    "    self.img_dec = nn.Sequential(\n",
    "      Conv2dBlock(64, 32*2*2, 3, 1, 1),\n",
    "      nn.PixelShuffle(2),\n",
    "      Conv2dBlock(32, 32*2*2, 3, 1, 1),\n",
    "      nn.PixelShuffle(2),\n",
    "      nn.Conv2d(32, 3*2*2, 3, 1, 1),\n",
    "      nn.PixelShuffle(2),\n",
    "    ).to(device)\n",
    "    \n",
    "    self.sim_core_enc = nn.Sequential(\n",
    "      nn.ConvTranspose2d(hidden_dim, 256, 4, 2, 1),\n",
    "      nn.GroupNorm(32, 256),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "      nn.GroupNorm(16, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "      nn.GroupNorm(8, 64),\n",
    "      nn.ReLU(),\n",
    "    ).to(device)\n",
    "    \n",
    "    self.num_steps = 8\n",
    "\n",
    "    self.decoder = nn.ModuleList([GatedCNN(64+32, 64).to(device) for _ in range(self.num_steps)])\n",
    "    self.posterior = nn.ModuleList([GatedCNN(64*2, 64).to(device) for _ in range(self.num_steps)])\n",
    "    self.prior = nn.ModuleList([GatedCNN(64*2, 64).to(device) for _ in range(self.num_steps)])\n",
    "    \n",
    "    self.gaussian_p = GaussianWithConv2d(64, 32).to(device)\n",
    "    self.gaussian_q = GaussianWithConv2d(64, 32).to(device)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  def init_states(self, B):\n",
    "    \n",
    "    h_p = torch.zeros(B, 64, 8, 8, device=device, dtype=torch.float)\n",
    "    h_q = torch.zeros(B, 64, 8, 8, device=device, dtype=torch.float)\n",
    "    h_rec = torch.zeros(B, 64, 8, 8, device=device, dtype=torch.float)\n",
    "    \n",
    "    return h_p, h_q, h_rec\n",
    "  \n",
    "  def forward(self, sim_core_h, x_t, is_training=True):\n",
    "    \n",
    "    B = x_t.shape[0]\n",
    "    \n",
    "    h_p, h_q, h_rec = self.init_states(B)\n",
    "    \n",
    "    sim_core_h = sim_core_h.unsqueeze(-1).unsqueeze(-1)\n",
    "    sim_core_h_enc = self.sim_core_enc(sim_core_h)\n",
    "    \n",
    "    rec_err = x_t.new_zeros(x_t.shape)\n",
    "    rec_x = x_t.new_zeros(x_t.shape)\n",
    "    \n",
    "    kl_loss = 0.\n",
    "    \n",
    "    for i in range(self.num_steps):\n",
    "      \n",
    "      if i == 0:\n",
    "        for _ in range(4):\n",
    "          h_p = self.prior[i](h_p, sim_core_h_enc)\n",
    "      else:\n",
    "        h_p = self.prior[i](h_p, sim_core_h_enc)\n",
    "      \n",
    "      # x_t_enc = self.img_enc(x_t)\n",
    "      \n",
    "      if is_training:\n",
    "        rec_err_enc = self.img_enc(torch.cat([x_t, rec_err], dim=1))\n",
    "        h_q = self.posterior[i](h_q, rec_err_enc)\n",
    "        \n",
    "        mu_q, std_q = self.gaussian_q(h_q)\n",
    "        mu_p, std_p = self.gaussian_p(h_p)\n",
    "        z = self.sample(mu_q, std_q)\n",
    "        kl_loss = kl_loss + self.cal_kl(mu_p, std_p, mu_q, std_q)\n",
    "        \n",
    "        h_rec = self.decoder[i](h_rec, z)\n",
    "        x_hat = self.img_dec(h_rec)\n",
    "        rec_x = rec_x + x_hat\n",
    "        rec_err = x_t - rec_x\n",
    "\n",
    "      else:\n",
    "        \n",
    "        mu_p, std_p = self.gaussian_p(h_p)\n",
    "        z = self.sample(mu_p, std_p)\n",
    "      \n",
    "        h_rec = self.decoder[i](h_rec, z)\n",
    "        x_hat = self.img_dec(h_rec)\n",
    "        rec_x = rec_x + x_hat\n",
    "\n",
    "      rec_x = rec_x.sigmoid()\n",
    "\n",
    "    if is_training:\n",
    "\n",
    "      constraint = self.constraint(x_t, rec_x)\n",
    "      return rec_x, constraint.mean(), kl_loss.sum(dim=(1,2,3)).mean()\n",
    "\n",
    "    else:\n",
    "      return rec_x\n",
    "        \n",
    "  def constraint(self, x, rec):\n",
    "    # kappa is pixel space error threshold\n",
    "    return torch.sum(torch.pow(rec - x, 2), dim = (1,2,3)) - self.kappa * 64 * 64 * 3\n",
    "\n",
    "  def sample(self, mu, std):\n",
    "    \n",
    "    noise = torch.empty_like(mu).normal_()\n",
    "    \n",
    "    return mu + std * noise\n",
    "  \n",
    "  def cal_kl(self, mu_p, std_p, mu_q, std_q):\n",
    "    \n",
    "    var_ratio = (std_q / std_p) ** 2\n",
    "    \n",
    "    return 0.5 * (((mu_q - mu_p) / std_p) ** 2 + (var_ratio - 1) - var_ratio.log())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from enum import Enum\n",
    "from threading import Thread\n",
    "from queue import Empty\n",
    "\n",
    "\n",
    "class SummaryType(Enum):\n",
    "    SCALAR = 1\n",
    "    HISTOGRAM = 2\n",
    "    VIDEO = 3\n",
    "    IMAGE = 4\n",
    "    FIGURE = 5\n",
    "    GRAPH = 6\n",
    "\n",
    "\n",
    "# Not working asynchronously\n",
    "class Statistics(Thread):\n",
    "    \"\"\"Writes the statistics of the async processes into a tensorboard\"\"\"\n",
    "\n",
    "    def __init__(self, writer_dir, statistics_queue, nb_episodes):\n",
    "\n",
    "        super(Statistics, self).__init__()\n",
    "\n",
    "        self.exit = False\n",
    "\n",
    "        self.stats_queue = statistics_queue\n",
    "        self.nb_episodes = nb_episodes\n",
    "\n",
    "        self._writer = SummaryWriter(log_dir=writer_dir)\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        super(Statistics, self).run()\n",
    "\n",
    "        # Make sure that all the logs are pushed to the tensorboard\n",
    "        last_step = 0\n",
    "        while True:\n",
    "\n",
    "            try:\n",
    "                summary_type, tag, data = self.stats_queue.get(timeout=1)\n",
    "            except Empty:\n",
    "                if self.exit:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            # Push the informations\n",
    "            step = self.nb_episodes.value\n",
    "\n",
    "            frames = step * 100\n",
    "\n",
    "            if summary_type == summary_type.SCALAR:\n",
    "                self._writer.add_scalar(tag=tag, scalar_value=data, global_step=frames)\n",
    "\n",
    "            elif summary_type == summary_type.HISTOGRAM:\n",
    "                self._writer.add_histogram(\n",
    "                    tag=tag, values=data, global_step=frames, bins=\"tensorflow\"\n",
    "                )\n",
    "\n",
    "            elif summary_type == summary_type.FIGURE:\n",
    "                self._writer.add_figure(tag=tag, figure=frames, global_step=step)\n",
    "\n",
    "            elif summary_type == summary_type.IMAGE:\n",
    "                if data.dim() > 3:\n",
    "                    self._writer.add_images(\n",
    "                        tag=tag, img_tensor=data, global_step=frames, dataformats=\"NCHW\"\n",
    "                    )\n",
    "                else:\n",
    "                    self._writer.add_image(\n",
    "                        tag=tag, img_tensor=data, global_step=frames, dataformats=\"CHW\"\n",
    "                    )\n",
    "\n",
    "            elif summary_type == summary_type.VIDEO:\n",
    "                self._writer.add_video(tag=tag, vid_tensor=data, global_step=frames, fps=4)\n",
    "\n",
    "            elif summary_type == summary_type.GRAPH:\n",
    "                self._writer.add_graph(model=data)\n",
    "\n",
    "        self._writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.multiprocessing as mp\n",
    "# from modules import *\n",
    "import numpy as np\n",
    "import queue\n",
    "# from logger import SummaryType\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from pyvirtualdisplay import Display\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import imageio\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import deque, defaultdict, namedtuple\n",
    "# from env_utils import *\n",
    "import gzip\n",
    "import pickle\n",
    "from glob import glob\n",
    "import pdb\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "Trajectory = namedtuple(\n",
    "    \"Trajectory\",\n",
    "    [\n",
    "        \"agent_view\",\n",
    "        \"map_top_down\",\n",
    "        \"a\",\n",
    "        \"pos\",\n",
    "        \"rot\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "class Memory:\n",
    "  def __init__(self,id: int,num_steps,):\n",
    "    self.id = id\n",
    "    self.agent_view = torch.zeros(1 + num_steps, 3, 64, 64, dtype=torch.float) #num of steps the agent moved gives those many views!\n",
    "    self.map_top_down = torch.zeros(1 + num_steps, 3, 64, 64, dtype=torch.float) #similar to above!\n",
    "    self.a = torch.zeros(1 + num_steps, 1, dtype=torch.float) #action that agent took in each step!\n",
    "    self.pos = torch.zeros(1 + num_steps, 2, dtype=torch.float) #x and z coridinates of the agent each step!\n",
    "    self.rot = torch.zeros(1 + num_steps, dtype=torch.float) \n",
    "    self.step = 0\n",
    "    self.num_steps = num_steps\n",
    "    self.id = id\n",
    "\n",
    "  def add(\n",
    "    self,\n",
    "    agent_view: torch.Tensor,\n",
    "    map_top_down: torch.Tensor,\n",
    "    a: torch.Tensor,\n",
    "    pos: torch.Tensor,\n",
    "    rot: torch.Tensor,\n",
    "  ):\n",
    "    self.agent_view[self.step].copy_(agent_view)\n",
    "    self.map_top_down[self.step].copy_(map_top_down)\n",
    "    self.a[self.step].copy_(a)\n",
    "    self.pos[self.step].copy_(pos)\n",
    "    self.rot[self.step].copy_(rot)\n",
    "    self.step += 1\n",
    "  \n",
    "  def reset(self):\n",
    "    self.step = 0\n",
    "\n",
    "  def to(self, device):\n",
    "    self.agent_view.to(device)\n",
    "    self.map_top_down.to(device)\n",
    "    self.a.to(device)\n",
    "    self.pos.to(device)\n",
    "    self.rot.to(device)\n",
    "\n",
    "  def enqueue(self):\n",
    "    assert self.step == (self.num_steps +1), \"actor {} has mistake in traj length\".format(self.id)\n",
    "    return Trajectory(\n",
    "      agent_view=self.agent_view.clone().to(device),\n",
    "      map_top_down=self.map_top_down.clone().to(device),\n",
    "      a=self.a.clone().to(device),\n",
    "      pos=self.pos.clone().to(device),\n",
    "      rot=self.rot.clone().to(device),\n",
    "    )\n",
    "\n",
    "  def save(self, filename):\n",
    "    traj = self.enqueue()\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "      pickle.dump(traj, f)\n",
    "\n",
    "class Actor(object):\n",
    "\n",
    "  def __init__(\n",
    "    self,\n",
    "    id,\n",
    "    q,\n",
    "    nb_episodes,\n",
    "    timeout=10\n",
    "  ):\n",
    "\n",
    "    self.id = id\n",
    "\n",
    "    self.timeout = timeout\n",
    "\n",
    "    self.q = q\n",
    "\n",
    "    #todo: what is mp.Event()\n",
    "    self.completion = mp.Event()\n",
    "    self.p = mp.Process(target=self._act,\n",
    "                            name='actor_test')\n",
    "\n",
    "    self.memory = Memory(id, lu)\n",
    "    self.episode_counter = nb_episodes\n",
    "\n",
    "\n",
    "  def _act(self):\n",
    "\n",
    "    try:\n",
    "      print(\"Actor {} started.\".format(self.id))\n",
    "\n",
    "\n",
    "      file_prex = ['./Datasets/50k/actor-{}-'.format(i) for i in range(1, 26)]\n",
    "      gened_files = [glob(f + '*') for f in file_prex]\n",
    "      num_gened_files = np.array([len(f) for f in gened_files])\n",
    "      less_than_2000 = np.where(num_gened_files < 2000)[0]\n",
    "\n",
    "      id_old = less_than_2000[self.id-1] + 1\n",
    "      traj_no = num_gened_files[less_than_2000[self.id-1]]\n",
    "      self.id = less_than_2000[self.id-1] + 1 + 25 # self.id idx starts from 1\n",
    "\n",
    "      print(\"actor-{} starts re-gen {} from traj-{}\".format(self.id, id_old, traj_no))\n",
    "\n",
    "      # todo: dataset\n",
    "      display = Display(backend='xvnc', size=(64,64), visible=0, rfbport=5854+self.id)\n",
    "      display.start()\n",
    "      env = UnityEnvironment(file_name=\"RC.x86_64\", worker_id=self.id, seed=self.id, timeout_wait=1000)\n",
    "#       env = UnityEnvironment(file_name=\"RC.x86_64\", seed=1, timeout_wait=1000)  \n",
    "      dtype = torch.float\n",
    "      episode_reward = 0\n",
    "      episode_n = 0\n",
    "      duration = 0\n",
    "\n",
    "      # while not self.learner.completion.is_set():\n",
    "      while traj_no < 2000:\n",
    "\n",
    "        traj_no += 1\n",
    "\n",
    "        traj_id = (self.id, traj_no)\n",
    "\n",
    "        self.memory.reset()\n",
    "\n",
    "        step = 0\n",
    "        act_step = 0\n",
    "        num_steps = 0\n",
    "        action = np.array([1])\n",
    "        action_prev = action\n",
    "        env.reset()\n",
    "        while step < 100 + 1:\n",
    "          print(\"Entered into some while\")\n",
    "\n",
    "          decision, _ = env.get_steps('My Behavior?team=0')\n",
    "\n",
    "          agent_view = decision.obs[0][0] # 64, 64, 3\n",
    "\n",
    "          vector_obs = decision.obs[1]\n",
    "\n",
    "          agent_pos, agent_rot = dec_agent_pos_rot(vector_obs[0, :6])\n",
    "          building_pos, building_scale = dec_building_pos_scale(vector_obs[0, 6:])\n",
    "\n",
    "          if act_step >= num_steps:\n",
    "            action, num_steps = self.sample_action(agent_rot, agent_pos,\n",
    "                                              building_pos, building_scale)\n",
    "            act_step = 0\n",
    "            action_prev = action\n",
    "          else:\n",
    "            action = action_prev\n",
    "\n",
    "          env.set_actions('My Behavior?team=0', action.reshape(1, 1))\n",
    "          env.step()\n",
    "          act_step = act_step + 1\n",
    "\n",
    "          # todo: normalize position\n",
    "          if step == 0:\n",
    "            map_top_down = dec_top_down_map(vector_obs[0, 6:])\n",
    "            map_ground = np.array([239, 176, 131]) / 255. # ground color is hard coded\n",
    "            map_top_down = map_top_down + (1. - (map_top_down > 0.)) * map_ground\n",
    "            map_top_down = torch.tensor(map_top_down, device=device, dtype=dtype).permute(2, 0, 1)\n",
    "          \n",
    "          agent_view = torch.tensor(agent_view, device=device, dtype=dtype).permute(2, 0, 1) # unity output pixel value [0, 1]\n",
    "          pos = np.array([agent_pos[0], agent_pos[2]])\n",
    "          pos = torch.tensor(pos, device=device, dtype=dtype)\n",
    "          rot = torch.tensor(agent_rot[1] % 360, device=device, dtype=dtype)\n",
    "\n",
    "          self.memory.add(agent_view, map_top_down, torch.tensor(action).float(), pos, rot) # belief state at t, agent_view at t+1\n",
    "\n",
    "          if ((traj_no-1) % 1000 == 0) and (self.id < 2):\n",
    "            if step == lu:\n",
    "              im = Image.fromarray((map_top_down * 255).permute(1,2,0).cpu().numpy().astype(np.uint8))\n",
    "              im.save('./image_samples/map_top_down-actor{}-traj{}-step100.png'.format(self.id, traj_no))\n",
    "              print(\"saved!!\")  \n",
    "              traj_map = plot_traj(map_top_down.permute(1,2,0).cpu().numpy(), self.memory.pos.cpu().numpy())\n",
    "              im = Image.fromarray((traj_map).astype(np.uint8))\n",
    "              im.save('./image_samples/traj_map-actor{}-traj{}-step0.png'.format(self.id, traj_no))\n",
    "              print(\"saved!!\") \n",
    "              imageio.mimsave('./image_samples/sample-actor{}-traj{}-step0.gif'.format(self.id, traj_no),\n",
    "                              np.array(self.memory.agent_view.permute(0,2,3,1).cpu()).reshape(-1, 64, 64, 3)*255.)\n",
    "              print(\"saved!!\") \n",
    "          step += 1\n",
    "          duration += 1\n",
    "\n",
    "\n",
    "        self.episode_counter.value += 1\n",
    "        while True:\n",
    "\n",
    "          try:\n",
    "\n",
    "            file_name = './Datasets/50k/actor-{}-traj-{}.pkl'.format(self.id, traj_no)\n",
    "            self.memory.save(file_name)\n",
    "            # self.q.put(self.memory.enqueue(), timeout=self.timeout)\n",
    "            if traj_no % 100 == 0:\n",
    "              print(\"Actor {} upload trajectory {} successfully.\".format(self.id, traj_no))\n",
    "            break\n",
    "\n",
    "          except queue.Full:\n",
    "            continue\n",
    "\n",
    "      env.close()\n",
    "      display.stop()\n",
    "      self.completion.set()\n",
    "      return\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "      env.close()\n",
    "      display.stop()\n",
    "      self.completion.set()\n",
    "      return\n",
    "\n",
    "    except Exception as e:\n",
    "      env.close()\n",
    "      raise e\n",
    "\n",
    "  def sample_action(self, agent_rot, agent_pos, building_pos, building_scale):\n",
    "    min_dis, angle = comp_min_distance_angle(agent_pos, building_pos, building_scale)\n",
    "\n",
    "    def _sample_action(building_angle, agent_rot, agent_pos,\n",
    "                      building_pos, building_scale, vel=1.5):\n",
    "      num_steps = 1\n",
    "      agent_pos_x = agent_pos[0]\n",
    "      agent_pos_z = agent_pos[2]\n",
    "      \n",
    "      action = np.array([1])\n",
    "      vel_x = np.cos((90 - agent_rot[1]) / 180 * np.pi) * vel\n",
    "      vel_z = np.sin((90 - agent_rot[1]) / 180 * np.pi) * vel\n",
    "      \n",
    "      pos_x = agent_pos_x + vel_x\n",
    "      pos_z = agent_pos_z + vel_z\n",
    "      \n",
    "      agent_pos_ = np.array([pos_x, agent_pos[1], pos_z])\n",
    "      \n",
    "      min_dis, building_angle = comp_min_distance_angle(agent_pos_, building_pos, building_scale)\n",
    "      \n",
    "      \n",
    "      agent_rot_ = (-agent_rot[1] + 90) % 360 # opposite rotation direction, agent facing y+ is 0 rotation\n",
    "      angle_diff = abs(agent_rot_ - building_angle)\n",
    "      \n",
    "      _, angle_diff_all = agent_building_angle(agent_pos_, agent_rot_, building_pos, building_scale)\n",
    "      go_out = (angle_diff_all > 90) * (angle_diff_all < 260)\n",
    "      \n",
    "      i = 0\n",
    "      while (abs(pos_z) > 35) or (abs(pos_x) > 35) or ((min_dis < 7.) and (angle_diff < 50 or angle_diff > 300)) or go_out.all():\n",
    "        action_prob = np.array([0.2, 0.2, .2, 0.2, 0.2])\n",
    "        action = np.random.choice(np.arange(5), size=1, p=action_prob) + 1\n",
    "\n",
    "        if (action == 4) or (action == 5):\n",
    "          if (abs(pos_z > 33) and abs(pos_x > 33)):\n",
    "            num_steps = 6\n",
    "          else:\n",
    "            num_steps = np.random.choice([1, 2, 3, 4, 5, 6], p=np.array([0.15, 0.15, 0.15, 0.15, 0.15, 0.25]))\n",
    "        else:\n",
    "          num_steps = 1\n",
    "            \n",
    "        if action == 1:\n",
    "          rot = 0\n",
    "          vel = 1.5\n",
    "        if action == 2:\n",
    "          rot = 30\n",
    "          vel = 1.5\n",
    "        if action == 3:\n",
    "          rot = -30\n",
    "          vel = 1.5\n",
    "        if action == 4:\n",
    "          rot = 30 * num_steps\n",
    "          vel = 0\n",
    "        if action == 5:\n",
    "          rot = -30 * num_steps\n",
    "          vel = 0\n",
    "          \n",
    "        agent_rot_ = agent_rot[1]\n",
    "        pos_x_ = agent_pos_x\n",
    "        pos_z_ = agent_pos_z\n",
    "        min_dis_ = min_dis\n",
    "          \n",
    "        if action == 2 or action == 3:\n",
    "          rot = rot / 5\n",
    "          for _ in range(5): # unity takes 5 small steps\n",
    "            agent_rot_ = agent_rot_ + rot\n",
    "\n",
    "            vel_x = np.cos((90 - agent_rot_) / 180 * np.pi) * vel / 5.\n",
    "            vel_z = np.sin((90 - agent_rot_) / 180 * np.pi) * vel / 5.\n",
    "            pos_x_ = pos_x_ + vel_x\n",
    "            pos_z_ = pos_z_ + vel_z\n",
    "            \n",
    "          rot = rot * 5\n",
    "            \n",
    "        else:\n",
    "          agent_rot_ = agent_rot_ + rot\n",
    "\n",
    "          vel_x = np.cos((90 - agent_rot_) / 180 * np.pi) * vel\n",
    "          vel_z = np.sin((90 - agent_rot_) / 180 * np.pi) * vel\n",
    "\n",
    "          pos_x_ = pos_x_ + vel_x\n",
    "          pos_z_ = pos_z_ + vel_z\n",
    "\n",
    "        agent_pos_ = np.array([pos_x_, agent_pos[1], pos_z_])\n",
    "        min_dis_, building_angle =  comp_min_distance_angle(agent_pos_, building_pos, building_scale)\n",
    "\n",
    "        agent_rot_ = (-agent_rot_ + 90) % 360 # opposite rotation direction, agent facing y+ is 0 rotation\n",
    "        angle_diff = abs(agent_rot_ - building_angle)\n",
    "        \n",
    "        _, angle_diff_all = agent_building_angle(agent_pos_, agent_rot_, building_pos, building_scale)\n",
    "        go_out = (angle_diff_all > 90) * (angle_diff_all < 260)\n",
    "\n",
    "        pos_x = pos_x_\n",
    "        pos_z = pos_z_\n",
    "        min_dis = min_dis_\n",
    "      \n",
    "        if i > 10:\n",
    "          action_prob = np.array([0.2, 0.2, .2, .2, .2])\n",
    "          action = np.random.choice(np.arange(5), size=1, p=action_prob) + 1\n",
    "          break\n",
    "        i += 1 \n",
    "    \n",
    "      return action , num_steps\n",
    "\n",
    "    return _sample_action(angle, agent_rot, agent_pos, building_pos, building_scale)\n",
    "\n",
    "    \n",
    "  def start(self):\n",
    "    if debug:\n",
    "      self._act()\n",
    "    else:\n",
    "      self.p.start()\n",
    "\n",
    "\n",
    "  def terminate(self):\n",
    "    self.p.terminate()\n",
    "\n",
    "\n",
    "  def join(self):\n",
    "\n",
    "    self.p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mp.Queue(maxsize = 25)\n",
    "update_counter = Counter(init_val=0)\n",
    "nb_episodes = mp.Value(\"i\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = []\n",
    "num_actors=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_actors):\n",
    "    actors.append(Actor(i+1, q,\n",
    "                        nb_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Actor at 0x7f8bec18b810>,\n",
       " <__main__.Actor at 0x7f8bec2fd090>,\n",
       " <__main__.Actor at 0x7f8bec18b2d0>,\n",
       " <__main__.Actor at 0x7f8bec19bc90>,\n",
       " <__main__.Actor at 0x7f8bec18bb50>,\n",
       " <__main__.Actor at 0x7f8bec19bb90>]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8bec278e10>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = Display(backend=\"xvnc\", size=(64,64), visible=0, rfbport=5879)\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8bec278e10>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in actors:\n",
    "    a.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in actors:\n",
    "    a.completion.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in actors:\n",
    "    a.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in actors:\n",
    "    a.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISPLAY was already unset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8c30147d90>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'unity' # deepmindlab\n",
    "\n",
    "log_path = './log/' + env + '/mem/50k'\n",
    "exp_name ='exp'\n",
    "num_actors = 6\n",
    "\n",
    "queue_maxsize = 25\n",
    "lu = 100\n",
    "lo = 32\n",
    "traj_no_total = 2000\n",
    "max_update = 1000000\n",
    "batch_size = 24\n",
    "\n",
    "rho_bar = 1.\n",
    "c_bar = 1.\n",
    "gamma = 0.99\n",
    "clip_reward = False\n",
    "\n",
    "grad_clip_norm = 10.\n",
    "init_lr = 0.0002\n",
    "epoch = 1000\n",
    "\n",
    "policy_loss_c = 1.\n",
    "v_loss_c = 0.5\n",
    "entropy_c = 0.00015\n",
    "model_loss_c = 0.1\n",
    "\n",
    "action_repeat = 6\n",
    "action_dim = 9\n",
    "hidden_dim = 512\n",
    "act_emb_dim = 128\n",
    "max_frame = 6e4\n",
    "\n",
    "latent_dim = 16\n",
    "draw_step = 8\n",
    "\n",
    "# memory\n",
    "code_size = 1024\n",
    "memory_size = 64\n",
    "dim_s = 128\n",
    "\n",
    "map_dec_type = 'pixel' # deconv-complex, deconv_simple\n",
    "mem_type = 'static'\n",
    "\n",
    "model_save_path = 'model_saved'\n",
    "\n",
    "kappa = 1e-3\n",
    "\n",
    "if env == 'unity':\n",
    "  map_size = [100., 100.]\n",
    "  pos_dim = (100 // 20)**2 # 5X5 grids\n",
    "else:\n",
    "  map_size = [1000., 1000.]\n",
    "  pos_dim = 1000 // 10\n",
    "rot_dim = 360 // 18\n",
    "debug = False\n",
    "\n",
    "level_cache_dir = '/tmp/level_cache'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-1baceacf4cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISPLAY was already unset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f8c3673aed0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
